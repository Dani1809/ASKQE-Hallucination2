{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# COSE DA FARE:\n",
        "\n",
        "\n",
        "1.   Migliora qualita PERTUBAAZIONI\n",
        "\n",
        "2.   Trova Metriche più autorevoli\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IuP1Ad4X3h6W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHmS1nY_QLgj",
        "outputId": "7c5b0bee-7c90-480b-d0a3-4021d4388578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ASKQE-Hallucination2'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 89 (delta 36), reused 27 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (89/89), 188.03 KiB | 7.83 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AlessiaCicca/ASKQE-Hallucination2.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elimina dati esistenti se serve"
      ],
      "metadata": {
        "id": "y4lnhIvzuuvz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cna-jV1KTDjI"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/ASKQE-Hallucination2/data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libera Memoria"
      ],
      "metadata": {
        "id": "N5pCPzHYu1Zu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TznzNBCA9ZHb",
        "outputId": "1ecb9903-b7e5-4202-8b83-ec261b3c0320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free GPU: 0.00 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(f\"Free GPU: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsWbNmfkL5_3"
      },
      "source": [
        "# TRANSLATION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u /content/ASKQE-Hallucination2/translate.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data.json \\\n",
        "  --output_path /content/ASKQE-Hallucination2/data/src_mt.jsonl \\\n",
        "  --source_language \"eng\" \\\n",
        "  --target_language \"ita\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYSumJTNd_ag",
        "outputId": "e3e8c709-a379-459d-c7bc-a662c6cd3581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOAD] facebook/nllb-200-distilled-600M\n",
            "tokenizer_config.json: 100% 564/564 [00:00<00:00, 4.01MB/s]\n",
            "sentencepiece.bpe.model: 100% 4.85M/4.85M [00:00<00:00, 6.03MB/s]\n",
            "tokenizer.json: 100% 17.3M/17.3M [00:00<00:00, 17.6MB/s]\n",
            "special_tokens_map.json: 3.55kB [00:00, 16.2MB/s]\n",
            "config.json: 100% 846/846 [00:00<00:00, 4.15MB/s]\n",
            "2026-01-17 08:14:30.808348: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768637670.832339     404 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768637670.839850     404 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768637670.853825     404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768637670.853860     404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768637670.853864     404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768637670.853869     404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 08:14:30.857884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "pytorch_model.bin: 100% 2.46G/2.46G [00:15<00:00, 160MB/s]\n",
            "model.safetensors:  45% 1.12G/2.46G [00:15<00:08, 154MB/s]\n",
            "generation_config.json: 100% 189/189 [00:00<00:00, 658kB/s]\n",
            "model.safetensors: 100% 2.46G/2.46G [00:28<00:00, 87.7MB/s]\n",
            "[STEP] Loading dataset: /content/ASKQE-Hallucination2/data.json\n",
            "[OK] JSONL with 3 samples\n",
            "  [1/3] Translated text: Relazioni pubblicate dalla Cina e dall'Italia suggeriscono che i fatto...\n",
            "  [2/3] Translated text: Inoltre, in alcuni casi, la riapertura delle scuole dopo un periodo di...\n",
            "  [3/3] Translated text: Le chiusure scolastiche nella città di Oita, in Giappone, hanno ridott...\n",
            "[INFO] Saving results to /content/ASKQE-Hallucination2/data/src_mt.jsonl\n",
            " TRANSLATION COMPLETED SUCCESSFULLY!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw_GR6pbL9Ds"
      },
      "source": [
        "# PERTUBATION ON THE TRANSLATION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u /content/ASKQE-Hallucination2/perturbMistral.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data/src_mt.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/data/src_mt_perturb.jsonl \\\n",
        "  --perturbation_type entity_injection"
      ],
      "metadata": {
        "id": "JASGAEbgzTMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4b24cc-cee7-46d8-8e1f-ea92bad5d9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Output directory ready: /content/ASKQE-Hallucination2/data\n",
            "tokenizer_config.json: 2.10kB [00:00, 9.53MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 876kB/s]\n",
            "tokenizer.json: 1.80MB [00:00, 69.5MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.80MB/s]\n",
            "[DEBUG] pad_token was None → set to eos_token\n",
            "config.json: 100% 596/596 [00:00<00:00, 4.06MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768637744.335959     798 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768637744.341910     798 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768637744.357109     798 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768637744.357142     798 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768637744.357147     798 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768637744.357153     798 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "model.safetensors.index.json: 25.1kB [00:00, 84.1MB/s]\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.94G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:   0% 0.00/4.54G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   0% 711k/4.94G [00:00<1:27:43, 939kB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 754k/5.00G [00:01<3:37:19, 383kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:   0% 816k/4.54G [00:02<3:30:28, 359kB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 32.2M/4.94G [00:02<05:27, 15.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 9.56M/5.00G [00:02<17:14, 4.82MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   1% 44.9M/5.00G [00:03<04:36, 17.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   2% 86.5M/5.00G [00:05<03:52, 21.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 74.0M/4.94G [00:07<07:59, 10.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   3% 153M/5.00G [00:07<03:06, 25.9MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 141M/4.94G [00:08<03:58, 20.2MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   5% 244M/5.00G [00:08<02:01, 39.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 336M/4.94G [00:09<01:20, 57.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   6% 287M/5.00G [00:09<01:49, 42.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 403M/4.94G [00:10<01:18, 58.1MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 539M/4.94G [00:11<00:54, 80.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   7% 354M/5.00G [00:11<01:58, 39.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:   1% 67.9M/4.54G [00:11<12:09, 6.13MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:   8% 421M/5.00G [00:15<02:50, 26.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 740M/4.94G [00:15<01:10, 59.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  10% 488M/5.00G [00:21<04:10, 18.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 874M/4.94G [00:21<01:44, 38.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  11% 555M/5.00G [00:22<03:04, 24.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 135M/4.54G [00:22<12:08, 6.05MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  12% 622M/5.00G [00:23<02:21, 31.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:   7% 336M/4.54G [00:23<03:33, 19.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  14% 689M/5.00G [00:24<01:58, 36.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 403M/4.54G [00:24<02:50, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  15% 756M/5.00G [00:25<01:36, 44.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 470M/4.54G [00:25<02:16, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 1.01G/4.94G [00:31<02:42, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.08G/4.94G [00:32<02:15, 28.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 841M/5.00G [00:37<04:44, 14.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.14G/4.94G [00:38<03:00, 21.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  19% 941M/5.00G [00:38<03:06, 21.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  20% 1.02G/5.00G [00:39<02:22, 27.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 604M/4.54G [00:40<02:12, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 606M/4.54G [00:42<04:42, 13.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.21G/4.94G [00:42<03:02, 20.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  22% 1.11G/5.00G [00:42<02:14, 29.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 673M/4.54G [00:48<04:53, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  25% 1.24G/5.00G [00:48<02:23, 26.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  16% 740M/4.54G [00:54<05:04, 12.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.28G/4.94G [00:54<04:58, 12.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 807M/4.54G [00:54<03:48, 16.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  26% 1.31G/5.00G [00:56<03:27, 17.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  27% 1.36G/5.00G [01:10<03:24, 17.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 807M/4.54G [01:10<03:48, 16.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.34G/4.94G [01:10<04:53, 12.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  28% 1.40G/5.00G [01:38<10:49, 5.53MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 874M/4.54G [01:39<13:48, 4.42MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.41G/4.94G [01:39<10:56, 5.38MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  29% 1.47G/5.00G [01:39<08:12, 7.16MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.48G/4.94G [01:40<08:24, 6.86MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  31% 1.54G/5.00G [01:40<06:07, 9.43MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.54G/4.94G [01:40<06:22, 8.90MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  32% 1.59G/5.00G [01:41<04:58, 11.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 941M/4.54G [01:47<11:49, 5.07MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  32% 1.60G/5.00G [01:47<06:36, 8.57MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.55G/4.94G [01:50<06:21, 8.90MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.61G/4.94G [01:51<06:53, 8.05MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  33% 1.67G/5.00G [01:51<05:22, 10.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.68G/4.94G [01:52<05:08, 10.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  22% 1.01G/4.54G [01:57<10:50, 5.43MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.14G/4.54G [01:58<05:52, 9.65MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.88G/4.94G [01:58<03:05, 16.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  28% 1.28G/4.54G [01:59<03:34, 15.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.95G/4.94G [01:59<02:32, 19.6MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.15G/4.94G [02:03<01:43, 26.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  34% 1.69G/5.00G [02:04<09:01, 6.11MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.34G/4.54G [02:08<04:14, 12.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  34% 1.72G/5.00G [02:08<08:59, 6.09MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.22G/4.94G [02:13<02:35, 17.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  35% 1.73G/5.00G [02:13<10:34, 5.15MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  34% 1.54G/4.54G [02:14<02:52, 17.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  35% 1.76G/5.00G [02:15<07:54, 6.82MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  37% 1.83G/5.00G [02:30<07:44, 6.82MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  35% 1.61G/4.54G [02:30<02:48, 17.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.29G/4.94G [02:30<02:31, 17.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  37% 1.87G/5.00G [02:50<12:53, 4.04MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.68G/4.54G [02:51<05:56, 8.03MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  40% 1.98G/5.00G [02:52<07:14, 6.95MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  40% 1.81G/4.54G [02:57<04:32, 10.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.35G/4.94G [02:57<06:23, 6.76MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  40% 2.01G/5.00G [02:57<07:35, 6.58MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  41% 1.88G/4.54G [02:57<03:42, 12.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.95G/4.54G [02:58<02:55, 14.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.49G/4.94G [02:58<04:13, 9.69MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  41% 2.05G/5.00G [03:03<07:18, 6.72MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  44% 2.02G/4.54G [03:03<02:55, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.55G/4.94G [03:03<03:53, 10.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  42% 2.12G/5.00G [03:04<04:51, 9.90MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  46% 2.08G/4.54G [03:09<03:03, 13.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.62G/4.94G [03:09<03:42, 10.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  44% 2.18G/5.00G [03:09<04:29, 10.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  47% 2.15G/4.54G [03:10<02:18, 17.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.69G/4.94G [03:10<02:51, 13.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.22G/4.54G [03:13<02:09, 17.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.75G/4.94G [03:13<02:31, 14.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  44% 2.19G/5.00G [03:13<05:20, 8.74MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  50% 2.28G/4.54G [03:13<01:34, 23.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.82G/4.94G [03:14<01:53, 18.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  46% 2.28G/5.00G [03:14<03:03, 14.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.89G/4.94G [03:15<01:28, 23.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  48% 2.40G/5.00G [03:15<01:43, 25.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  52% 2.35G/4.54G [03:15<01:22, 26.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  49% 2.43G/5.00G [03:19<02:22, 18.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  53% 2.42G/4.54G [03:23<02:10, 16.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  50% 2.52G/5.00G [03:24<02:09, 19.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.96G/4.94G [03:25<02:28, 13.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  51% 2.55G/5.00G [03:25<02:09, 18.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.09G/4.94G [03:29<01:43, 18.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  52% 2.58G/5.00G [03:29<02:39, 15.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  53% 2.65G/5.00G [03:34<02:31, 15.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.27G/4.94G [03:34<01:07, 24.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  56% 2.55G/4.54G [03:34<02:17, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  53% 2.66G/5.00G [03:34<02:31, 15.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.62G/4.54G [03:40<02:21, 13.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.34G/4.94G [03:40<01:21, 19.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  54% 2.70G/5.00G [03:40<03:27, 11.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  59% 2.69G/4.54G [03:41<01:47, 17.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  54% 2.71G/5.00G [03:42<03:40, 10.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.75G/4.54G [03:42<01:24, 21.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.41G/4.94G [03:43<01:16, 20.0MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.42G/4.94G [03:44<01:15, 20.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  55% 2.73G/5.00G [03:44<03:34, 10.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.56G/4.94G [03:45<00:41, 33.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.89G/4.54G [03:45<01:02, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.69G/4.94G [03:45<00:25, 48.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  55% 2.74G/5.00G [03:48<05:09, 7.30MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.83G/4.94G [03:49<00:23, 46.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  56% 2.78G/5.00G [03:49<03:02, 12.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.96G/4.94G [03:49<00:15, 64.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  58% 2.92G/5.00G [03:49<01:05, 31.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.96G/4.54G [03:50<01:10, 22.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.02G/4.54G [03:50<00:53, 28.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  61% 3.03G/5.00G [03:51<00:48, 40.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.16G/4.54G [03:52<00:34, 40.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.03G/4.94G [03:52<00:18, 49.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  61% 3.07G/5.00G [03:53<00:52, 36.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  63% 3.14G/5.00G [03:53<00:37, 49.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  64% 3.21G/5.00G [03:53<00:27, 65.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  65% 3.23G/5.00G [03:54<00:26, 66.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.09G/4.94G [03:54<00:19, 43.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.22G/4.54G [03:54<00:37, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  65% 3.25G/5.00G [03:54<00:33, 52.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  72% 3.29G/4.54G [03:55<00:29, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  66% 3.29G/5.00G [03:55<00:28, 59.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.16G/4.94G [03:55<00:17, 44.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.36G/4.54G [03:55<00:22, 52.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  67% 3.36G/5.00G [03:56<00:23, 70.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  67% 3.37G/5.00G [03:56<00:23, 70.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  75% 3.42G/4.54G [03:56<00:18, 61.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  77% 3.49G/4.54G [03:56<00:14, 74.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.56G/4.54G [03:57<00:10, 94.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.21G/4.94G [04:03<00:38, 19.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  69% 3.44G/5.00G [04:03<01:29, 17.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  70% 3.50G/5.00G [04:07<01:20, 18.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.27G/4.94G [04:07<00:34, 19.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  71% 3.55G/5.00G [04:07<00:58, 24.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  71% 3.57G/5.00G [04:07<00:49, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.62G/4.54G [04:07<00:49, 18.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.76G/4.54G [04:08<00:24, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  72% 3.60G/5.00G [04:08<00:52, 26.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.64G/5.00G [04:12<01:15, 18.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.83G/4.54G [04:12<00:28, 25.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.89G/4.54G [04:13<00:20, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.65G/5.00G [04:13<01:17, 17.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.34G/4.94G [04:14<00:39, 15.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  87% 3.96G/4.54G [04:14<00:15, 37.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.67G/5.00G [04:14<01:12, 18.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  74% 3.71G/5.00G [04:14<00:51, 25.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  74% 3.72G/5.00G [04:14<00:42, 29.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  89% 4.03G/4.54G [04:15<00:12, 41.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  75% 3.74G/5.00G [04:15<00:41, 30.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.09G/4.54G [04:15<00:08, 53.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  75% 3.75G/5.00G [04:15<00:40, 30.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  76% 3.79G/5.00G [04:16<00:28, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  77% 3.86G/5.00G [04:16<00:14, 78.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  78% 3.92G/5.00G [04:19<00:25, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.41G/4.94G [04:19<00:36, 14.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  80% 3.99G/5.00G [04:19<00:17, 58.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  81% 4.04G/5.00G [04:19<00:13, 72.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.16G/4.54G [04:19<00:12, 31.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.47G/4.94G [04:20<00:25, 18.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  81% 4.07G/5.00G [04:20<00:14, 63.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  93% 4.23G/4.54G [04:20<00:07, 39.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.14G/5.00G [04:20<00:10, 82.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  95% 4.29G/4.54G [04:21<00:05, 49.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  84% 4.19G/5.00G [04:21<00:08, 94.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  85% 4.26G/5.00G [04:21<00:05, 127MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  86% 4.32G/5.00G [04:21<00:04, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  88% 4.38G/5.00G [04:22<00:03, 160MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  88% 4.40G/5.00G [04:22<00:04, 148MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.54G/4.94G [04:22<00:18, 21.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  89% 4.47G/5.00G [04:22<00:03, 138MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.61G/4.94G [04:22<00:11, 28.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  96% 4.34G/4.54G [04:23<00:04, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  90% 4.50G/5.00G [04:24<00:07, 63.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.41G/4.54G [04:24<00:03, 41.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.67G/4.94G [04:24<00:08, 30.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  91% 4.54G/5.00G [04:25<00:07, 63.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  92% 4.59G/5.00G [04:25<00:04, 83.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  93% 4.65G/5.00G [04:25<00:02, 117MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  94% 4.72G/5.00G [04:25<00:02, 138MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.74G/4.94G [04:25<00:05, 36.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  95% 4.74G/5.00G [04:26<00:02, 122MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.81G/4.94G [04:26<00:02, 45.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors:  96% 4.81G/5.00G [04:26<00:01, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors:  99% 4.47G/4.54G [04:26<00:01, 38.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00003.safetensors: 100% 4.54G/4.54G [04:27<00:00, 17.0MB/s]\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  98% 4.88G/5.00G [04:27<00:01, 113MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.88G/4.94G [04:29<00:01, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.94G/4.94G [04:29<00:00, 18.3MB/s]\n",
            "Fetching 3 files:  33% 1/3 [04:29<08:59, 269.69s/it]\n",
            "\n",
            "model-00002-of-00003.safetensors:  99% 4.93G/5.00G [04:29<00:01, 51.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00003.safetensors: 100% 5.00G/5.00G [04:30<00:00, 18.5MB/s]\n",
            "Fetching 3 files: 100% 3/3 [04:30<00:00, 90.08s/it] \n",
            "Loading checkpoint shards: 100% 3/3 [00:54<00:00, 18.15s/it]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 536kB/s]\n",
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "[DEBUG] Input tokens shape: torch.Size([1, 321])\n",
            "[OK] ex1 | pert_mt\n",
            "In the relationships published by China and Italy, factors of risk for severe COVID-19 include underlying health conditions, but data describing the underlying health conditions of COVID-19 patients in the United States have not been reported yet.\n",
            "\n",
            "Output:\n",
            "In the relationships published by China and Italy, factors of risk for severe COVID-19 include underlying health conditions, but data describing the underlying health conditions of COVID-19 patients in the United States have not been reported yet. **Dr. Jane Smith**, a leading epidemiologist, has emphasized the importance of collecting and analyzing this data.\n",
            "--------------------------------------------------------------------------------\n",
            "[DEBUG] Input tokens shape: torch.Size([1, 270])\n",
            "[OK] ex2 | pert_mt\n",
            "Inoltre, in alcuni casi, la riapertura delle scuole dopo un periodo di chiusura ha portato ad un aumento dei tassi di infezione di persona non identificata.\n",
            "--------------------------------------------------------------------------------\n",
            "[DEBUG] Input tokens shape: torch.Size([1, 304])\n",
            "[OK] ex3 | pert_mt\n",
            "Le chiusure scolastiche nella città di Oita, in Giappone, hanno ridotto con successo il numero di studenti infetti al picco dell'infezione; tuttavia, non è stato scoperto che le scuole chiuse abbiano ridotto significativamente il numero totale di studenti infetti di Professor Tanaka.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoP9mRtPgU-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e390844c-faee-4c62-dc60-a12d9df56b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Output directory ready: /content/ASKQE-Hallucination2/data\n",
            "[DEBUG] pad_token was None → set to eos_token\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768583922.599768   12519 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768583922.614546   12519 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768583922.660874   12519 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768583922.660925   12519 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768583922.660934   12519 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768583922.660940   12519 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading checkpoint shards: 100% 3/3 [00:53<00:00, 17.80s/it]\n",
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "[DEBUG] Input tokens shape: torch.Size([1, 307])\n",
            "[OK] ex1 | pert_mt\n",
            "Relazioni pubblicate dalla Cina e dall'Italia suggeriscono che i fattori di rischio per la malattia grave di COVID-19 includono condizioni di salute sottostanti e un tasso di obesità del 35%.\n",
            "\n",
            "(Note: The new numerical value \"35%\" is added without changing the meaning or structure of the sentence.)\n",
            "--------------------------------------------------------------------------------\n",
            "[DEBUG] Input tokens shape: torch.Size([1, 256])\n",
            "[OK] ex2 | pert_mt\n",
            "Inoltre, in alcuni casi, la riapertura delle scuole dopo un periodo di chiusura ha portato ad un aumento del 15% dei tassi di infezione.\n",
            "--------------------------------------------------------------------------------\n",
            "[DEBUG] Input tokens shape: torch.Size([1, 290])\n",
            "[OK] ex3 | pert_mt\n",
            "Le chiusure scolastiche nella città di Oita, in Giappone, hanno ridotto con successo il numero di studenti infetti al picco dell'infezione a 500; tuttavia, non è stato scoperto che le scuole chiuse abbiano ridotto significativamente il numero totale di studenti infetti.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python -u /content/ASKQE-Hallucination2/perturbMistral.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data/src_mt.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/data/src_mt_perturb.jsonl \\\n",
        "  --perturbation_type numerical_injection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3iVhEljyUS3"
      },
      "outputs": [],
      "source": [
        "!python -u /content/ASKQE-Hallucination/perturbMistral.py \\\n",
        "  --input_path /content/ASKQE-Hallucination/data/src_mt.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination/data/src_mt_perturb.jsonl \\\n",
        "  --perturbation_type over_specification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq_x0oN-MFPA"
      },
      "source": [
        "# BACKTRANSLATION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u /content/ASKQE-Hallucination2/backtranslate.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data/src_mt_perturb.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt.jsonl \\\n",
        "  --source_language ita \\\n",
        "  --target_language eng\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G5qfa_O2RSX",
        "outputId": "40e837be-61d6-4330-84b2-48f36fb26c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[LOAD] facebook/nllb-200-distilled-600M\n",
            "2026-01-17 08:23:08.344562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768638188.380835    2726 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768638188.391735    2726 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768638188.414218    2726 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768638188.414259    2726 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768638188.414265    2726 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768638188.414270    2726 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 08:23:08.420354: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[STEP] Loading dataset: /content/ASKQE-Hallucination2/data/src_mt_perturb.jsonl\n",
            "[OK] JSONL with 3 samples\n",
            "  [1/3] BT: In the relationships published by China and Italy, factors of risk for...\n",
            "  [2/3] BT: In addition, in some cases, reopening schools after a period of closur...\n",
            "  [3/3] BT: School closures in the city of Oita, Japan, successfully reduced the n...\n",
            "[INFO] Saving results to /content/ASKQE-Hallucination2/data/src_mt_perturb_bt.jsonl\n",
            " BACK-TRANSLATION COMPLETED SUCCESSFULLY!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUESTION GENERATION"
      ],
      "metadata": {
        "id": "RmszxFBzeCAu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUT7mK6L0v3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb8fdb5-0183-4843-fa30-fc89db8d18f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 08:59:41.729156: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768640381.748323   12177 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768640381.753484   12177 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768640381.767482   12177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640381.767506   12177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640381.767575   12177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640381.767594   12177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 08:59:41.771744: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.16s/it]\n",
            "[bt] In the relationships published by China and Italy, factors of risk for severe COVID-19 include underlying health conditions, but data describing the underlying health conditions of COVID-19 patients in the United States have not yet been reported. Output: In the relationships published by China and Italy, factors of risk for severe COVID-19 include underlying health conditions, but data describing the underlying health conditions of COVID-19 patients in the United States have not yet been reported. **Dr. Jane Smith**, a leading epidemiologist, has emphasized the importance of collecting and analyzing this data.\n",
            "> Raw output:\n",
            "[\"What factors of risk for severe COVID-19 are included?\", \"What data is lacking for the United States?\", \"Who emphasized the importance of collecting and analyzing the data?\", \"What aspect of the data collection is highlighted by Dr. Jane Smith?\"])\n",
            "[ERROR] JSON parse failed: Extra data: line 1 column 249 (char 248)\n",
            "[ERROR] Output was: [\"What factors of risk for severe COVID-19 are included?\", \"What data is lacking for the United States?\", \"Who emphasized the importance of collecting and analyzing the data?\", \"What aspect of the dat\n",
            "> Parsed 1 questions:\n",
            "  1. [\"What factors of risk for severe COVID-19 are included?\", \"What data is lacking for the United States?\", \"Who emphasized the importance of collecting and analyzing the data?\", \"What aspect of the data collection is highlighted by Dr. Jane Smith?\"])\n",
            "============================================================\n",
            "[bt] In addition, in some cases, reopening schools after a period of closure has led to an increase in the rates of unidentified infection.\n",
            "> Raw output:\n",
            "[\"What has led to an increase in the rates of unidentified infection?\", \"In what scenarios has reopening schools after closure been observed?\", \"What type of reopening was considered in the sentence?\"]\n",
            "> Parsed 3 questions:\n",
            "  1. What has led to an increase in the rates of unidentified infection?\n",
            "  2. In what scenarios has reopening schools after closure been observed?\n",
            "  3. What type of reopening was considered in the sentence?\n",
            "============================================================\n",
            "[bt] School closures in the city of Oita, Japan, successfully reduced the number of students infected at the peak of the infection; however, it was not found that closed schools significantly reduced the total number of students infected by Professor Tanaka.\n",
            "> Raw output:\n",
            "[\"What did school closures achieve?\", \"What was not found regarding closed schools?\", \"What did Professor Tanaka study about school closures?\"]\n",
            "> Parsed 3 questions:\n",
            "  1. What did school closures achieve?\n",
            "  2. What was not found regarding closed schools?\n",
            "  3. What did Professor Tanaka study about school closures?\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!python -u /content/ASKQE-Hallucination2/qg.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg.jsonl \\\n",
        "  --prompt_path /content/ASKQE-Hallucination2/prompt.json \\\n",
        "  --prompt_key qg_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUESTION ANSWERING"
      ],
      "metadata": {
        "id": "crPjiUQLvGlQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WzTipm8AcGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b915c9a0-ee80-4a4a-c212-a10cec4d29b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 09:00:37.383516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768640437.409915   12405 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768640437.418129   12405 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768640437.450335   12405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640437.450361   12405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640437.450366   12405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640437.450371   12405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:00:37.454203: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.50s/it]\n",
            "✅ QA (SRC + BT) completed correctly.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python ASKQE-Hallucination2/qa.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg_qa.jsonl \\\n",
        " --prompt_path /content/ASKQE-Hallucination2/prompt.json\\\n",
        "--prompt_key qa_prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATION"
      ],
      "metadata": {
        "id": "vJgfXj6twMD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python /content/ASKQE-Hallucination2/ucr.py \\\n",
        "--input_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg_qa.jsonl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIUNtUtawNa3",
        "outputId": "3856f628-eb6e-4f2e-ef60-4ce697c4551a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STEP] Loading dataset: /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg_qa.jsonl\n",
            "[OK] Loaded 3 samples\n",
            "[HALLUCINATION]\n",
            "SRC: No Answer\n",
            "BT : 'Unidentified infection' refers to\n",
            "----------------------------------------\n",
            "[HALLUCINATION]\n",
            "SRC: No Answer\n",
            "BT : University of Tokyo\n",
            "----------------------------------------\n",
            "\n",
            "UCR Hallucination Score: 0.1333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHECK"
      ],
      "metadata": {
        "id": "I153kMHJyc0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer-aware Question Generation"
      ],
      "metadata": {
        "id": "yJbZXDxH29H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u /content/ASKQE-Hallucination2/checkqg.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg_qa.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg_qa_checkqg.jsonl \\\n",
        "  --prompt_path /content/ASKQE-Hallucination2/prompt.json \\\n",
        "  --prompt_key qg_prompt_check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiZCbGzNyeeG",
        "outputId": "91c51993-e8fe-4325-dfa2-c81ef5027c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are given:\n",
            "- a question\n",
            "- an answer\n",
            "\n",
            "Your task is to generate YES/NO verification questions\n",
            "to check whether the information in the answer\n",
            "is explicitly supported by the ORIGINAL source text.\n",
            "\n",
            "Rules:\n",
            "- Output MUST be a valid JSON array: [\"Question 1?\", \"Question 2?\", \"Question 3?\"]\n",
            "- Generate 1 to 3 YES/NO questions.\n",
            "- Each question must be answerable with YES or NO.\n",
            "- Each question must verify ONE specific fact in the answer.\n",
            "- Do NOT ask open-ended questions.\n",
            "- Do NOT add explanations.\n",
            "- Output ONLY a JSON array of strings.\n",
            "\n",
            "Examples:\n",
            "Question: \"What symptoms does the patient have?\"\n",
            "Answer: \"fever and headache\"\n",
            "→ \"The patient has fever and headache?\"\n",
            "\n",
            "Question: \"Which university does he attend?\"\n",
            "Answer: \"University of Tokyo\"\n",
            "→ [\"Does he attend the University of Tokyo?\"]\n",
            "\n",
            "Question: {{question}}\n",
            "Answer: {{answer}}\n",
            "\n",
            "Verification questions:\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 09:01:54.193374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768640514.222863   12749 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768640514.231667   12749 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768640514.271204   12749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640514.271246   12749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640514.271254   12749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640514.271261   12749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:01:54.277486: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.10s/it]\n",
            "[OK] ex1 → 0 contrastive questions\n",
            "[OK] ex2 → 3 contrastive questions\n",
            "[OK] ex3 → 3 contrastive questions\n",
            "✅ Contrastive YES/NO generation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YES/NO answer on src"
      ],
      "metadata": {
        "id": "kbLkIpnB3AeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u /content/ASKQE-Hallucination2/checkqa.py \\\n",
        "  --input_path  /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg_qa_checkqg.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg_qa_checkqg_checkqa.jsonl \\\n",
        "  --prompt_path /content/ASKQE-Hallucination2/prompt.json\\\n",
        "  --prompt_key qa_prompt_check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA94ijfJ08nJ",
        "outputId": "a117b0fc-321d-463c-b57b-50586d800211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 09:04:49.911145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768640689.930163   13485 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768640689.935245   13485 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768640689.950072   13485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640689.950095   13485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640689.950099   13485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768640689.950104   13485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:04:49.954120: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.27s/it]\n",
            "[YES/NO QA] ex2\n",
            "  Q: Was reopening of schools after a period of closure mentioned in the source text?\n",
            "  A: Yes\n",
            "  Q: Is an increase in unidentified infections caused by what is mentioned in the source text?\n",
            "  A: No\n",
            "  Q: [\"How did reopening schools affect the rate of unidentified infections?\"?]\n",
            "  A: No\n",
            "[YES/NO QA] ex3\n",
            "  Q: Was the effect of school closures on the number of students infected discussed in the source text?\n",
            "  A: Yes\n",
            "  Q: Are school closures known to reduce the total number of students infected?\n",
            "  A: No\n",
            "  Q: Did Professor Tanaka investigate closed schools and student infections?\n",
            "  A: Yes\n",
            "✅ Contrastive YES/NO QA on SRC completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "9UZZvwVq3HYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ASKQE-Hallucination2/compute_contrastative_metrics.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data/src_mt_perturb_bt_qg_qa_checkqg_checkqa.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEy94fJs3IkE",
        "outputId": "6bb1c679-2649-4dcb-8b28-6cc392eef272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== CONTRASTIVE HALLUCINATION METRICS ======\n",
            "Total contrastive questions : 12\n",
            "Yes                        : 5\n",
            "No                         : 4\n",
            "No Answer                  : 3\n",
            "---------------------------------------------\n",
            "CHR (No / All)             : 0.3333\n",
            "CHR_verified (No / Y+N)    : 0.4444\n",
            "CHR_strict ((N+NA) / All)  : 0.5833\n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg30OiJRbreh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVE"
      ],
      "metadata": {
        "id": "9gtqJ1Llw46o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p38sc_7sDws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c56671-f326-4998-e04c-30b5b76bebed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ASKQE-Hallucination2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ASKQE-Hallucination2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BdKz79_NnJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae78825-4df5-4a73-8614-990872eca30a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mdeleted:    dataNoPerturb/qa_bt.jsonl\u001b[m\n",
            "\t\u001b[31mdeleted:    dataNoPerturb/qa_src.jsonl\u001b[m\n",
            "\t\u001b[31mmodified:   dataNoPerturb/src_mt_bt.jsonl\u001b[m\n",
            "\t\u001b[31mmodified:   dataNoPerturb/src_mt_bt_qg.jsonl\u001b[m\n",
            "\t\u001b[31mdeleted:    dataNoPerturb/src_multillm_clean.jsonl\u001b[m\n",
            "\t\u001b[31mmodified:   prompt.json\u001b[m\n",
            "\t\u001b[31mmodified:   qa.py\u001b[m\n",
            "\t\u001b[31mmodified:   qg.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mdataNoPerturb/src_mt.jsonl\u001b[m\n",
            "\t\u001b[31mdataNoPerturb/src_mt_bt_qg_qa.jsonl\u001b[m\n",
            "\t\u001b[31mdataNoPerturb/src_mt_bt_qg_qa_checkqg.jsonl\u001b[m\n",
            "\t\u001b[31mdataNoPerturb/src_mt_bt_qg_qa_checkqg_checkqa.jsonl\u001b[m\n",
            "\t\u001b[31mtranslatellm.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKLxHGfJNp5l"
      },
      "outputs": [],
      "source": [
        "!git add .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rrTnbRdN27A"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"alessia.ciccaglione02@gmail.com\"\n",
        "!git config --global user.name \"AlessiaCicca\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC5O11dDNtFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314a3b1d-bcb1-4342-bb6d-0675e0c34906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main b4f7aa2] Add Without Perturbation\n",
            " 13 files changed, 277 insertions(+), 102 deletions(-)\n",
            " delete mode 100644 dataNoPerturb/qa_bt.jsonl\n",
            " delete mode 100644 dataNoPerturb/qa_src.jsonl\n",
            " create mode 100644 dataNoPerturb/src_mt.jsonl\n",
            " rewrite dataNoPerturb/src_mt_bt.jsonl (90%)\n",
            " rewrite dataNoPerturb/src_mt_bt_qg.jsonl (93%)\n",
            " create mode 100644 dataNoPerturb/src_mt_bt_qg_qa.jsonl\n",
            " create mode 100644 dataNoPerturb/src_mt_bt_qg_qa_checkqg.jsonl\n",
            " create mode 100644 dataNoPerturb/src_mt_bt_qg_qa_checkqg_checkqa.jsonl\n",
            " delete mode 100644 dataNoPerturb/src_multillm_clean.jsonl\n",
            " create mode 100644 translatellm.py\n"
          ]
        }
      ],
      "source": [
        "!git commit -m \"Add Without Perturbation \"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TOKEN"
      ],
      "metadata": {
        "id": "oo8MUQ0FE57s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0al-o8YOAua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c966001-d04e-465f-ef62-b03920285f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 20, done.\n",
            "Counting objects:   5% (1/20)\rCounting objects:  10% (2/20)\rCounting objects:  15% (3/20)\rCounting objects:  20% (4/20)\rCounting objects:  25% (5/20)\rCounting objects:  30% (6/20)\rCounting objects:  35% (7/20)\rCounting objects:  40% (8/20)\rCounting objects:  45% (9/20)\rCounting objects:  50% (10/20)\rCounting objects:  55% (11/20)\rCounting objects:  60% (12/20)\rCounting objects:  65% (13/20)\rCounting objects:  70% (14/20)\rCounting objects:  75% (15/20)\rCounting objects:  80% (16/20)\rCounting objects:  85% (17/20)\rCounting objects:  90% (18/20)\rCounting objects:  95% (19/20)\rCounting objects: 100% (20/20)\rCounting objects: 100% (20/20), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:   7% (1/13)\rCompressing objects:  15% (2/13)\rCompressing objects:  23% (3/13)\rCompressing objects:  30% (4/13)\rCompressing objects:  38% (5/13)\rCompressing objects:  46% (6/13)\rCompressing objects:  53% (7/13)\rCompressing objects:  61% (8/13)\rCompressing objects:  69% (9/13)\rCompressing objects:  76% (10/13)\rCompressing objects:  84% (11/13)\rCompressing objects:  92% (12/13)\rCompressing objects: 100% (13/13)\rCompressing objects: 100% (13/13), done.\n",
            "Writing objects:   7% (1/13)\rWriting objects:  15% (2/13)\rWriting objects:  23% (3/13)\rWriting objects:  30% (4/13)\rWriting objects:  38% (5/13)\rWriting objects:  53% (7/13)\rWriting objects:  61% (8/13)\rWriting objects:  69% (9/13)\rWriting objects:  76% (10/13)\rWriting objects:  84% (11/13)\rWriting objects:  92% (12/13)\rWriting objects: 100% (13/13)\rWriting objects: 100% (13/13), 6.32 KiB | 3.16 MiB/s, done.\n",
            "Total 13 (delta 9), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (9/9), completed with 5 local objects.\u001b[K\n",
            "To https://github.com/AlessiaCicca/ASKQE-Hallucination2.git\n",
            "   b92f4df..b4f7aa2  main -> main\n"
          ]
        }
      ],
      "source": [
        "!git push origin main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLq8fL0GR2Qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4082eab4-e172-4db2-d4f6-422bf348e548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ],
      "source": [
        "!git status\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qea8nezLiLlh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# USANDO UN MODELLO LLM PER TRADUZIONE CON PARAMETRI SCARSI E SENZA FARE POI LE PERTUBAZIONI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/ASKQE-Hallucination2/dataNoPerturb/"
      ],
      "metadata": {
        "id": "EETK7cDdO55M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation with Qwen/Qwen2.5-0.5B-Instruct"
      ],
      "metadata": {
        "id": "I8ahJkpdPE-M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFeeHMFhib-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0a5022-5bcf-4db0-e2a3-eb4effdd466b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOAD] Qwen/Qwen2.5-0.5B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 09:26:19.769731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768641979.788864   18982 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768641979.793956   18982 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768641979.815511   18982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768641979.815535   18982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768641979.815541   18982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768641979.815545   18982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:26:19.822289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[STEP] Loading dataset: /content/ASKQE-Hallucination2/data.json\n",
            "[OK] JSONL with 3 samples\n",
            "[1/3] MT: Published reports from China and Italy indicate that risks for severe COVID-19 d...\n",
            "[2/3] MT: Additionally, in some cases, the reopening of schools after a period of closure ...\n",
            "[3/3] MT: School closings in the city of Oita, Japan, had been successful in reducing the ...\n",
            "[INFO] Saving results to /content/ASKQE-Hallucination2/dataNoPerturb/src_mt.jsonl\n",
            "✅ TRANSLATION COMPLETED SUCCESSFULLY!\n"
          ]
        }
      ],
      "source": [
        "!python -u /content/ASKQE-Hallucination2/translatellm.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/data.json \\\n",
        "  --output_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt.jsonl \\\n",
        "  --source_language \"Italian\" \\\n",
        "  --target_language \"English\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No Perturbation...BackTranslation directly"
      ],
      "metadata": {
        "id": "uEvP2IJtPjPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u /content/ASKQE-Hallucination2/backtranslate.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt.jsonl \\\n",
        "  --input_field mt \\\n",
        "  --source_language ita \\\n",
        "  --target_language eng\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElcEqXWaPqT5",
        "outputId": "7d197a34-e68c-4a42-92d3-13ab5ea5907a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "[LOAD] facebook/nllb-200-distilled-600M\n",
            "2026-01-17 09:39:04.413917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768642744.438169   22248 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768642744.445338   22248 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768642744.459644   22248 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768642744.459669   22248 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768642744.459673   22248 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768642744.459679   22248 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:39:04.463712: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[STEP] Loading dataset: /content/ASKQE-Hallucination2/dataNoPerturb/src_mt.jsonl\n",
            "[OK] JSONL with 3 samples\n",
            "  [1/3] BT: Published reports from China and Italy indicate that risks for severe ...\n",
            "  [2/3] BT: In addition, in some cases, the reopening of schools after a period of...\n",
            "  [3/3] BT: School closures in the city of Oita, Japan, had been successful in red...\n",
            "[INFO] Saving results to /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt.jsonl\n",
            " BACK-TRANSLATION COMPLETED SUCCESSFULLY!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Generation"
      ],
      "metadata": {
        "id": "hL3nQg_LP0RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u /content/ASKQE-Hallucination2/qg.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg.jsonl \\\n",
        "  --prompt_path /content/ASKQE-Hallucination2/prompt.json \\\n",
        "  --prompt_key qg_prompt"
      ],
      "metadata": {
        "id": "jh1FfSPjqYD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834c3107-cb56-4ed9-c040-fef3b6d3988f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 09:52:18.351246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768643538.379497   25648 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768643538.388684   25648 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768643538.422204   25648 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643538.422238   25648 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643538.422243   25648 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643538.422247   25648 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:52:18.426463: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:26<00:00, 13.03s/it]\n",
            "[DEBUG] Input sentence:\n",
            "Published reports from China and Italy indicate that risks for severe COVID-19 disease include underlying health conditions, but data about these underlying health conditions in U.S. patients are still pending.\n",
            "[DEBUG] JSONDecodeError: Extra data: line 1 column 154 (char 153)\n",
            "[DEBUG] Fallback split produced 1 questions\n",
            "[DEBUG] Final questions count: 1\n",
            "[DEBUG] Record written to file\n",
            "[DEBUG] Input sentence:\n",
            "In addition, in some cases, the reopening of schools after a period of closure has led to an increase in infection rates.\n",
            "[DEBUG] json.loads OK → type=<class 'list'>\n",
            "[DEBUG] Final questions count: 2\n",
            "[DEBUG] Record written to file\n",
            "[DEBUG] Input sentence:\n",
            "School closures in the city of Oita, Japan, had been successful in reducing the number of infected students during the peak period of infection; however, school closures did not appear to have significantly impacted the overall number of infected students.\n",
            "[DEBUG] json.loads OK → type=<class 'list'>\n",
            "[DEBUG] Final questions count: 3\n",
            "[DEBUG] Record written to file\n",
            "\n",
            "COMPLETED — Output file written successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Answering"
      ],
      "metadata": {
        "id": "aqUgWk-PP3dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python  /content/ASKQE-Hallucination2/qa.py \\\n",
        "--input_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg.jsonl \\\n",
        "--output_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg_qa.jsonl \\\n",
        " --prompt_path /content/ASKQE-Hallucination2/prompt.json\\\n",
        "--prompt_key qa_prompt\n"
      ],
      "metadata": {
        "id": "rCcZMrHPsjZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eec9155-8115-4bbb-8ba6-5ac8ada07ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using device: cuda\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 09:53:35.135800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768643615.165189   25978 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768643615.174584   25978 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768643615.207230   25978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643615.207262   25978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643615.207266   25978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643615.207270   25978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:53:35.211469: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:26<00:00, 13.03s/it]\n",
            "✅ QA (SRC + BT) completed correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{\"id\": \"ex3\", \"src\": \"School closures in the city of Oita, Japan, were found to have successfully decreased the number of infected students at the peak of infection; however closing schools was not found to have significantly decreased the total number of infected students.\", \"mt\": \"School closings in the city of Oita, Japan, had been successful in reducing the number of infected students during the peak period of infection; however, school closures did not appear to have significantly impacted the overall number of infected students.\", \"bt\": \"School closures in the city of Oita, Japan, had been successful in reducing the number of infected students during the peak period of infection; however, school closures did not appear to have significantly impacted the overall number of infected students.\", \"questions_bt\": [\"What was successful in reducing the number of infected students?\", \"What did school closures not impact?\", \"How did school closures affect the number of infected students during the peak period?\", \"What was the overall impact of school closures on infected students?\"], \"answers_src\": [\"Were school closures found to decrease the number of infected students at the peak of infection?\", \"Did school closures significantly decrease the total number of infected students?\", \"Was the success of decreasing the number of infected students due to school closures noted in the sentence?\", \"No Answer\"], \"answers_bt\": [\"Were school closures successful in reducing the number of infected students during the peak period?\", \"Did school closures have a significant impact on the overall number of infected students?\", \"No Answer\", \"No Answer\"]}\n"
      ],
      "metadata": {
        "id": "FuHpbYqiVYBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "nyrqIVfWRSj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python /content/ASKQE-Hallucination2/ucr.py \\\n",
        "--input_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg_qa.jsonl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28sqd1MzRT9X",
        "outputId": "42080d2d-3390-47b2-8e13-a3d39307256c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STEP] Loading dataset: /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg_qa.jsonl\n",
            "[OK] Loaded 3 samples\n",
            "\n",
            "UCR Hallucination Score: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer-aware Question Generation"
      ],
      "metadata": {
        "id": "dnFa9wu6QT6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python -u /content/ASKQE-Hallucination2/checkqg.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg_qa.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg_qa_checkqg.jsonl \\\n",
        "  --prompt_path /content/ASKQE-Hallucination2/prompt.json \\\n",
        "  --prompt_key qg_prompt_check\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VheodreBRZLL",
        "outputId": "6ab2003d-4768-4dc5-d714-4c61888b08a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 09:54:43.022079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768643683.063610   26282 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768643683.077302   26282 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768643683.119129   26282 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643683.119170   26282 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643683.119179   26282 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643683.119186   26282 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:54:43.125577: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:29<00:00, 14.70s/it]\n",
            "[OK] ex1 → 5 contrastive questions\n",
            "[OK] ex2 → 0 contrastive questions\n",
            "[OK] ex3 → 0 contrastive questions\n",
            "✅ Contrastive YES/NO generation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YES/NO Answer on src"
      ],
      "metadata": {
        "id": "CPNrEjPsQWLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python -u /content/ASKQE-Hallucination2/checkqa.py \\\n",
        "  --input_path  /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg_qa_checkqg.jsonl \\\n",
        "  --output_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg_qa_checkqg_checkqa.jsonl \\\n",
        "  --prompt_path /content/ASKQE-Hallucination2/prompt.json\\\n",
        "  --prompt_key qa_prompt_check\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvU2Eu_aQwRG",
        "outputId": "648453af-370d-49fb-f016-6a1c62877845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-17 09:55:40.251863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768643740.279391   26536 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768643740.286757   26536 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768643740.319259   26536 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643740.319291   26536 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643740.319296   26536 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768643740.319300   26536 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-17 09:55:40.324113: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:25<00:00, 12.90s/it]\n",
            "[YES/NO QA] ex1\n",
            "  Q: Is severe COVID-19 disease linked to underlying health conditions?\n",
            "  A: Yes\n",
            "  Q: Is the answer mentioning underlying health conditions?\n",
            "  A: Yes\n",
            "  Q: Is the data about underlying health conditions in U.S. patients still pending?\n",
            "  A: Yes\n",
            "  Q: Is China mentioned in the text?\n",
            "  A: Yes\n",
            "  Q: Is Italy mentioned in the text?\n",
            "  A: Yes\n",
            "✅ Contrastive YES/NO QA on SRC completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATION"
      ],
      "metadata": {
        "id": "cOF86ticYRcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ASKQE-Hallucination2/compute_contrastative_metrics.py \\\n",
        "  --input_path /content/ASKQE-Hallucination2/dataNoPerturb/src_mt_bt_qg_qa_checkqg_checkqa.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhcx7oT1YQ9m",
        "outputId": "fd7d2710-178e-455d-ccee-274faea0d0bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== CONTRASTIVE HALLUCINATION METRICS ======\n",
            "Total contrastive questions : 5\n",
            "Yes                        : 5\n",
            "No                         : 0\n",
            "No Answer                  : 0\n",
            "---------------------------------------------\n",
            "CHR (No / All)             : 0.0000\n",
            "CHR_verified (No / Y+N)    : 0.0000\n",
            "CHR_strict ((N+NA) / All)  : 0.0000\n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}